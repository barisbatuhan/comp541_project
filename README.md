# Context-Aware Attention Network for Image-Text Retrieval

**Author:** Barış Batuhan Topal
**Contact:** barisbatuhantopal@gmail.com / baristopal20@ku.edu.tr

## Description

This project is an unofficial implementation of the paper "Context-Aware Attention Network for Image-Text Retrieval" in Julia programming language. 

**Abstract of the Paper:** As a typical cross-modal problem,  image-text bi-directional retrieval relies heavily on the joint embeddinglearning and similarity measure for each image-text pair.It remains challenging because prior works seldom exploresemantic correspondences between modalities and seman-tic correlations in a single modality at the same time. In thiswork, we propose a unified Context-Aware Attention Net-work (CAAN), which selectively focuses on critical localfragments (regions and words) by aggregating the globalcontext. Specifically, it simultaneously utilizes global inter-modal alignments and intra-modal correlations to discoverlatent semantic relations. Considering the interactions be-tween images and sentences in the retrieval process, intra-modal correlations are derived from the second-order atten-tion of region-word alignments instead of intuitively com-paring the distance between original features. Our methodachieves fairly competitive results on two generic image-text retrieval datasets Flickr30K and MS-COCO.

## Useful Links

* https://openaccess.thecvf.com/content_CVPR_2020/papers/Zhang_Context-Aware_Attention_Network_for_Image-Text_Retrieval_CVPR_2020_paper.pdf[**Paper Link**]

* https://docs.google.com/document/d/1fF8Y2ZG3iQvLiHqBY47O8yGQFobWY9JDyNRvDlUqJPQ/edit?usp=sharing[**Research Log**]

* https://docs.google.com/presentation/d/1lBw68_IdbSe_0n2KAlupRnDulvfzNrUMwx3sBkNl9p8/edit?usp=sharing[**Final Presentation**]

* https://docs.google.com/spreadsheets/d/1Si1-91wCge3aq7liSTSFxGuJb3fO_-xHlAIzQkaLEyU/edit?usp=sharing[**Data Sheet**]

* https://www.overleaf.com/read/pbtyskcsdgyt[**Tech Report**]



